{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "# importing regex\n",
    "import re\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1=\"https://www.biba.in/girls/?page=35\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find all <div> elements with classes \"col-6\", \"col-sm-6\", and \"col-md-3\"\n",
    "# product_items = driver.find_elements(By.CSS_SELECTOR, \"div.col-6.col-sm-6.col-md-3\")\n",
    "\n",
    "# i=0\n",
    "# # Iterate through each <div> element\n",
    "# for item in product_items:\n",
    "#     # Find the <a> element within the <div> with the specified class\n",
    "#     product_link = item.find_element(By.CSS_SELECTOR, 'a.link.d-lg-none')\n",
    "\n",
    "#     # Extract the relative URL from the href attribute\n",
    "#     relative_url = product_link.get_attribute(\"href\")\n",
    "\n",
    "#     # Construct the absolute URL by appending the relative URL to the base URL\n",
    "#     absolute_url = relative_url\n",
    "\n",
    "#     i=i+1\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element found but unable to click. Continuing...\n",
      "Element found but unable to click. Continuing...\n",
      "Element found but unable to click. Continuing...\n",
      "Element found but unable to click. Continuing...\n",
      "Element found but unable to click. Continuing...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Open a CSV file in write mode\n",
    "with open('BibaWomen_Kids.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['Sno','Brandname','Category','link','ProductType','ProductName','ProductCode','price','color1','color2','color3','color4','WearType','MaterialType','reviews','size1','Size2','size3','Size4','size5','size6','CountryOfOrigin','ReturnTime','Occasion'])\n",
    "    \n",
    "\n",
    "    # Find all <li> elements with class \"product-item\"\n",
    "    product_items = driver.find_elements(By.CSS_SELECTOR, \"div.col-6.col-sm-6.col-md-3\")\n",
    "    \n",
    "    # Initialize Sno counter\n",
    "    sno = 1\n",
    "    \n",
    "\n",
    "\n",
    "    # Iterate through each <li> element\n",
    "    for item in product_items:\n",
    "        # Find the <a> element within the <li> with the specified href\n",
    "        product_link = item.find_element(By.CSS_SELECTOR, 'a.link.d-lg-none')\n",
    "\n",
    "        # Extract the relative URL from the href attribute\n",
    "        relative_url = product_link.get_attribute(\"href\")\n",
    "\n",
    "        # Construct the absolute URL by appending the relative URL to the base URL\n",
    "        absolute_url = relative_url\n",
    "\n",
    "        driver.execute_script(\"window.open('{}', '_blank');\".format(absolute_url))\n",
    "\n",
    "        # Switch to the new tab\n",
    "         # Wait for the page to load\n",
    "        time.sleep(0.5)  # Adjust this delay if needed\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        # Find the <h1> element with the specified class\n",
    "\n",
    "\n",
    "        # Find the product product_name\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        try:\n",
    "            product_name_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[1]/div/h1')\n",
    "            \n",
    "            product_name = product_name_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            product_name = \"NA\"\n",
    "\n",
    "        # Find the product_price\n",
    "        try:\n",
    "            product_price_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[2]/div/div/div/div/span/span[1]')\n",
    "            product_price = product_price_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            product_price = \"NA\"\n",
    "\n",
    "          #click desc\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        try:\n",
    "            search_1 = driver.find_element(By.XPATH,'//*[@id=\"accordion\"]/div/h2[1]')      \n",
    "            search_1.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Element not found or unable to click. Continuing...\")\n",
    "        except ElementClickInterceptedException:\n",
    "            print(\"Element found but unable to click. Continuing...\")\n",
    "\n",
    "        # Find the product product_type\n",
    "        try:\n",
    "            product_type_element = driver.find_element(By.XPATH, '//*[@id=\"productDetails\"]/div[2]/div/div/ul/li[1]')\n",
    "            product_type = product_type_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            product_type = \"NA\"\n",
    "\n",
    "        # Find the MaterialType\n",
    "        try:\n",
    "            MaterialType_element = driver.find_element(By.XPATH, '//*[@id=\"productDetails\"]/div[2]/div/div/ul/li[9]/span')\n",
    "            MaterialType = MaterialType_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            MaterialType = \"NA\"\n",
    "\n",
    "        # Find the color1\n",
    "\n",
    "                    \n",
    "        try:\n",
    "            color1_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[3]/div[2]/div/div/div/a[1]/span[2]')\n",
    "            color1 = color1_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            color1 = \"NA\"\n",
    "        \n",
    "\n",
    "        # Find the color2\n",
    "\n",
    "        try:\n",
    "            color2_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[3]/div[2]/div/div/div/a[2]/span[2]')\n",
    "            color2 = color2_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            color2 = \"NA\"\n",
    "\n",
    "\n",
    "        try:\n",
    "            color3_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[3]/div[2]/div/div/div/a[3]/span[2]')\n",
    "            color3 = color3_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            color3 = \"NA\"\n",
    "\n",
    "\n",
    "         \n",
    "        # Find the color4\n",
    "\n",
    "        try:\n",
    "            color4_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[3]/div[2]/div/div/div/a[4]/span[2]')\n",
    "            color4 = color4_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            color4 = \"NA\"\n",
    "\n",
    "\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "           #click delv\n",
    "        try:\n",
    "            search_1 = driver.find_element(By.XPATH,'//*[@id=\"accordion\"]/div/h2[4]')      \n",
    "            search_1.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Element not found or unable to click. Continuing...\")\n",
    "        except ElementClickInterceptedException:\n",
    "            print(\"Element found but unable to click. Continuing...\")\n",
    "      \n",
    "\n",
    "        # Find the product_code\n",
    "        try:\n",
    "            product_code_element = driver.find_element(By.XPATH, '//*[@id=\"productDeclaration\"]/div/ul/li[1]/span')\n",
    "            product_code = product_code_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            product_code = \"NA\"\n",
    "\n",
    "\n",
    "        # Find the CountryOfOrigin\n",
    "        try:\n",
    "            CountryOfOrigin_element = driver.find_element(By.XPATH, '//*[@id=\"productDeclaration\"]/div/ul/li[5]/span')\n",
    "            CountryOfOrigin = CountryOfOrigin_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            CountryOfOrigin = \"NA\"\n",
    "\n",
    "        # Find the Size1\n",
    "\n",
    "        try:\n",
    "            Size1_element = driver.find_element(By.XPATH, '//*[@id=\"size_selector\"]/div[2]/div/div/a[1]')\n",
    "            Size1 = Size1_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Size1 = \"NA\"\n",
    "\n",
    "        # Find the Size2\n",
    "\n",
    "        try:\n",
    "            Size2_element = driver.find_element(By.XPATH, '//*[@id=\"size_selector\"]/div[2]/div/div/a[3]')\n",
    "            Size2 = Size2_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Size2 = \"NA\"\n",
    "\n",
    "        # Find the Size3\n",
    "\n",
    "        try:\n",
    "            Size3_element = driver.find_element(By.XPATH, '//*[@id=\"size_selector\"]/div[2]/div/div/a[5]')\n",
    "            Size3 = Size3_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Size3 = \"NA\"\n",
    "\n",
    "        # Find the Size4\n",
    "\n",
    "        try:\n",
    "            Size4_element = driver.find_element(By.XPATH, '//*[@id=\"size_selector\"]/div[2]/div/div/a[7]')\n",
    "            Size4 = Size4_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Size4 = \"NA\"\n",
    "\n",
    "        # Find the Size5\n",
    "\n",
    "        try:\n",
    "            Size5_element = driver.find_element(By.XPATH, '//*[@id=\"size_selector\"]/div[2]/div/div/a[9]')\n",
    "            Size5 = Size5_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Size5 = \"NA\"\n",
    "\n",
    "        # Find the Size6\n",
    "\n",
    "        try:\n",
    "            Size6_element = driver.find_element(By.XPATH, '//*[@id=\"size_selector\"]/div[2]/div/div/a[11]')\n",
    "            Size6 = Size6_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Size6 = \"NA\"\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "         \n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "        # Find the Reviews\n",
    "        try:\n",
    "            Reviews_element = driver.find_element(By.XPATH, '//*[@id=\"yotpo-bottomline-top-div\"]/div/div[1]/div[1]/span/span[6]')\n",
    "            Reviews = Reviews_element.text.strip().replace('\\n', ' ')\n",
    "            if Reviews =='0':\n",
    "                Reviews = \"NA\"\n",
    "        except NoSuchElementException:\n",
    "            Reviews = \"NA\"\n",
    "\n",
    "\n",
    "        try:\n",
    "            Returntime_element = driver.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[2]/div[2]/div[8]/div/div/ul/li[2]/h3')\n",
    "            Returntime = Returntime_element.text.strip().replace('\\n', ' ')\n",
    "        except NoSuchElementException:\n",
    "            Returntime = \"NA\"\n",
    "       \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        # Write Sno, link, and product name to the CSV file\n",
    "        csv_writer.writerow([sno,'BIBA','WoMen', absolute_url,product_type, product_name,product_code, product_price,color1,color2,color3,color4,'NA',MaterialType,Reviews,Size1,Size2,Size3,Size4,Size5,Size6,CountryOfOrigin,Returntime,'regular'])\n",
    "        \n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "        # Close the new tab\n",
    "        driver.close()\n",
    "\n",
    "        # Switch back to the original tab\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        # Increment Sno\n",
    "        sno += 1\n",
    "\n",
    "        # Wait for 200 milliseconds before proceeding to the next tab\n",
    "        time.sleep(0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
